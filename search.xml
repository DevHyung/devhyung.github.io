<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pyspark 스파크 프로그래밍 기초 학습</title>
      <link href="/2024/03/14/5-pyspark-4-%EC%B1%95%ED%84%B04-%EC%8A%A4%ED%8C%8C%ED%81%AC%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EA%B8%B0%EC%B4%88/"/>
      <url>/2024/03/14/5-pyspark-4-%EC%B1%95%ED%84%B04-%EC%8A%A4%ED%8C%8C%ED%81%AC%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EA%B8%B0%EC%B4%88/</url>
      
        <content type="html"><![CDATA[<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><blockquote><p>챕터4에서는 pyspark의 기본적인 RDD관련 내용이 나옴<br>page수가 많아서 걱정했는데 그냥 … 코드블럭과 기본적인 연산이<br>어떻게 일어나는지에 대한 하나하나의 설명이였다.<br>기초적인 내용이라 뒤의 내용에서 하나씩 참고해서 보면 좋을만한 내용이 있던 장</p></blockquote><hr><h1 id="Keywords-amp-Terms"><a href="#Keywords-amp-Terms" class="headerlink" title="Keywords &amp; Terms"></a>Keywords &amp; Terms</h1><ul><li>RDD(Resilient Destributed Dataset)</li><li>RDD transformation &amp; action = action때 spark는 일함 </li><li>Fault tolerant = MR가 대비해 spark가 error가 나면 어떻게 복구될까?를 생각</li><li>Lineage = RDD의 생성순서 </li><li>DAG(Directed Acyclic Graph) = 특정job이 돌기위해 실행되는 프로레스 </li><li>Transformations = Lazy operations = why? = 최적의 DAG를 Actions단계에서 찾기위해 </li></ul><hr><p>내용은 아래와 같다고 한다 </p><ul><li>RDD </li><li>RDD load at spark</li><li>RDD transformation &amp; action</li><li>RDD 연산</li></ul><p>분명 … 책의 소스코드는<br><a href="https://sparkusingpython.com/" target="_blank" rel="noopener">https://sparkusingpython.com/</a><br>와 <a href="https://github.com/sparktraining/spark_using_python" target="_blank" rel="noopener">https://github.com/sparktraining/spark_using_python</a> 에 있다는데…<br>깃허브는 살아있는데  sparkusingpython 사이트는 없어졌네 하하 …<br>깃허브는… 챕터별로 정리가된것도아니고 하하 이게 뭐지…</p><h2 id="RDDs"><a href="#RDDs" class="headerlink" title="RDDs"></a>RDDs</h2><ul><li>RDDs (Resilient Distributed Datasets) is Data Containers = 탄력적인 분산 데이터셋 = 데이터 컨테이너를 의미 </li><li>스파크의 모든 다른 프로세싱들은 RDD abstraction을 share함</li><li>transformations을 하든 섞든 뭘 하든 해서 새로운 RDDs를 만들고 할 수 있음 </li><li>Fault tolerant </li></ul><p>예제<br><img src="Pasted image 20240314194432.png" alt="예제"><br>여기서 에러만 디텍팅하고싶다<br>파일을 읽으면 Base RDD lines 가 생김 -&gt;<br>여기서 filter를 걸면 새로운 errors RDD 가 생김 -&gt;<br>count하는게 action 단계인거고 </p><p><img src="Pasted image 20240314194827.png" alt="예제"><br>물리적인 노드에서 발생하는 처리를 보면<br>driver와 다수의 worker<br>driver = main 함수 라고 생각<br>코드가 서밋되면 클러스터안에서 분배가 될거고<br>hdfs에서 파일을 읽으면 =&gt; 블럭단위로 분산되어서 저장 =&gt; 캐시가되면 워커의 메모리영역중<br>일부를 캐시영역으로<br>transformed RDD가 계속 생성이되면 그 결과값을 driver쪽으로 던져주는</p><p><img src="Pasted image 20240314195050.png" alt="예제"><br>그럼 여기서 Fault Tolerance란 뭐냐면<br>MR는 매번 I/O가 일어나니까 만약 중간에 에러가나면<br>이걸 다시 읽고 하고 하면됨<br>spark에선 rework를 어떻게하냐<br>만약 mapled RDD에서 만약 뻗었다 =&gt; 그럼 FilteredRDD부터 다시 수행함<br>이렇게해서 Fault Tolerance 를 보장함</p><p><img src="Pasted image 20240314200201.png" alt="예제"><br>연산에 대해서는<br>transformations 는 map filter groupby join 이런거 RDD로 다른 RDD를 만들어보다보니 Lazy operations<br>spark이 일을하는 단계는 Actions을 해야함 count, collect, save, show 이런것들 storage에 읽고쓰는거<br>왜 저걸 Lazy하게 할까 ? =&gt; (DAG = 특정잡이 돌기위해 실행되는 프로세스) 최적의 DAG를 Actions단계에서 찾기위해서<br>lineage는 RDD의 생성순서를 뜻하고</p><p><img src="Pasted image 20240314200508.png" alt="예제"></p><ul><li>처음의  RDD를 읽고 계속변환함 = Transformation = 새로운 RDD가 계속 생성</li><li>Lineage 트래킹하면서 fault tolerance 제공하는거고 </li><li>action이 일어나면 저장하든가 그럼</li></ul><p><img src="Pasted image 20240314200607.png" alt="예제"></p><ul><li>Transformation : 새로운 RDD를 생성한다</li><li>Actions : 드라이버쪽으로 결과를 리턴하거나 세이브하는것들 = spark이 일을하는 시점 </li></ul><p><img src="Pasted image 20240314200757.png" alt="예제"></p><ul><li>RDD -&gt; DF 오면서 분석석도가 뙤또이해짐 </li></ul>]]></content>
      
      
      <categories>
          
          <category> PySpark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 스터디 </tag>
            
            <tag> PySpark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[PySpark_#3] 파이썬을 활용한 스파크 프로그래밍, (3장/8장)</title>
      <link href="/2024/03/07/4-pyspark-3-%EC%B1%95%ED%84%B03-%EC%8A%A4%ED%8C%8C%ED%81%AC-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"/>
      <url>/2024/03/07/4-pyspark-3-%EC%B1%95%ED%84%B03-%EC%8A%A4%ED%8C%8C%ED%81%AC-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><blockquote><p>챕터3에서는 SPARK의 기본 아키텍처에 대한 설명이 나옴.<br>내용으로는 길어보였는데 flow를 따라서 가보니 각 컴퍼넌트별 역할이 명확하게 있어서…<br>실습 전 가볍게 이해하기에는 무리가 없었던 장.</p></blockquote><hr><h1 id="Keywords-amp-Terms"><a href="#Keywords-amp-Terms" class="headerlink" title="Keywords &amp; Terms"></a>Keywords &amp; Terms</h1><ul><li>RDD(Resilient Destributed Datase</li><li>DAG(Directed Acyclic Graph)</li></ul><hr><h1 id="What-is-spark"><a href="#What-is-spark" class="headerlink" title="What is spark?"></a>What is spark?</h1><h2 id="spark"><a href="#spark" class="headerlink" title="spark?"></a>spark?</h2><p><img src="Pasted image 20240307192446.png" alt="스파크 정의"><br>스파크 = Lightning-fast unified analytics engine</p><h2 id="장점"><a href="#장점" class="headerlink" title="장점"></a>장점</h2><ul><li>맵리듀스보다 더 빠르게 computing 할 수 있다 </li><li>디스크기준으론 10x, 인메모리 기준으로는 100x 빠르게 가능하겠다</li><li>기존하둡은 매번 요청이 있을때마다 디스크까지 내려가는데 그걸 인메모리에서 구현하겟다가 스팤</li></ul><h2 id="MR-vs-SPARK"><a href="#MR-vs-SPARK" class="headerlink" title="MR vs SPARK"></a>MR vs SPARK</h2><p><img src="Pasted image 20240307192753.png" alt="맵리듀스1"><br><img src="Pasted image 20240307192714.png" alt="맵리듀스2"><br>MR: 매번 디스크에서 읽고 메모리에서 쓰고 빠질거를 SPARK는 메모리에서 연산하고 끔 \<br>shuffle+sort는 네트워크 I/O가 필요한데 이 부분도 없어짐<br>코드스니펫 비교<br><img src="Pasted image 20240307192940.png" alt="맵리듀스 스파크 코드스니펫"></p><h1 id="spark-아키텍처"><a href="#spark-아키텍처" class="headerlink" title="spark 아키텍처"></a>spark 아키텍처</h1><p><img src="Pasted image 20240307193300.png" alt="스파크 아키텍쳐"></p><ol><li><code>클러스터매니저</code>로 인해 관리됨, 유저코드를 제출하는 걸 = spark-submit라 칭함</li><li>spark-submit을 하면 <code>Driver Process</code>가 뜨고 <code>Spark session</code>을 생성</li><li>그리고 다수의 <code>Executors</code>를 생성하고 정책은 (1)의 과정에서 정함 core, memory수 그런거 등등</li><li><code>Executors</code>들에서 내가 작성한 코드들이 분산실행 됨 </li></ol>]]></content>
      
      
      <categories>
          
          <category> PySpark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 스터디 </tag>
            
            <tag> PySpark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[PySpark_#2] 파이썬을 활용한 스파크 프로그래밍, (2장/8장)</title>
      <link href="/2024/02/26/3-pyspark-2-%EC%B1%95%ED%84%B02/"/>
      <url>/2024/02/26/3-pyspark-2-%EC%B1%95%ED%84%B02/</url>
      
        <content type="html"><![CDATA[<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><blockquote><p>챕터2에서는 OS별 스파크 설치와 언어별 실행 스크립트를 설명함.<br>AWS의 EC2와 EMR 인스턴스에 띄워보는등 on-premise와 cloud모두 설명</p></blockquote><hr><h1 id="Keywords-amp-Terms"><a href="#Keywords-amp-Terms" class="headerlink" title="Keywords &amp; Terms"></a>Keywords &amp; Terms</h1><ul><li>EMR(Elastic Map-Reduce)</li><li>YARN(Yet Another Resource Negotiator)</li><li>RDD(Resilient Destributed Dataset)</li></ul><hr><h1 id="스파크-배포-모드-개요"><a href="#스파크-배포-모드-개요" class="headerlink" title="스파크 배포 모드 개요"></a>스파크 배포 모드 개요</h1><p>일반적으로는</p><ul><li>Local</li><li>Standalone</li><li>YARN(hadoop)</li><li>mesos(apache)</li></ul><p>로 배포하고 리소스를 관리하는 방식만 다름 YARN, mesos같이 외부 스케줄러쓰면<br>로컬모드로 실행 or Spark Standalone 스케줄러 쓰면되는데,<br>이때 스파크 외부 종속성(?)이 제거된다고함 </p><p>기본적으론 \</p><ul><li><a href="https://spark.apache.org/docs/latest/" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/</a> </li><li><a href="https://wikidocs.net/26793" target="_blank" rel="noopener">https://wikidocs.net/26793</a></li></ul><p>여기가 설명은 더 잘나와있음</p><h2 id="언어별-실행-스크립트"><a href="#언어별-실행-스크립트" class="headerlink" title="언어별 실행 스크립트"></a>언어별 실행 스크립트</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bin 폴더 실행 파일 </span></span><br><span class="line">-rwxr-xr-x 1 root root 1099 Nov 16  2016 beeline</span><br><span class="line">-rw-r--r-- 1 root root 2143 Nov 16  2016 load-spark-env.sh</span><br><span class="line">-rwxr-xr-x 1 root root 3265 Nov 16  2016 pyspark       // 파이썬 </span><br><span class="line">-rwxr-xr-x 1 root root 1040 Nov 16  2016 run-example</span><br><span class="line">-rwxr-xr-x 1 root root 3126 Nov 16  2016 spark-class</span><br><span class="line">-rwxr-xr-x 1 root root 1049 Nov 16  2016 sparkR        // R</span><br><span class="line">-rwxr-xr-x 1 root root 3026 Nov 16  2016 spark-shell   // scala repl</span><br><span class="line">-rwxr-xr-x 1 root root 1075 Nov 16  2016 spark-sql     // spark on sql</span><br><span class="line">-rwxr-xr-x 1 root root 1050 Nov 16  2016 spark-submit  // scala jar</span><br></pre></td></tr></table></figure><h2 id="spark-submit-문법"><a href="#spark-submit-문법" class="headerlink" title="spark-submit 문법"></a>spark-submit 문법</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark-submit 실행 옵션 </span></span><br><span class="line">$ ./bin/spark-submit \</span><br><span class="line">  --class &lt;main-class&gt; \</span><br><span class="line">  --master &lt;master-url&gt; \</span><br><span class="line">  --deploy-mode &lt;deploy-mode&gt; \</span><br><span class="line">  --conf &lt;key&gt;=&lt;value&gt; \</span><br><span class="line">  ... <span class="comment"># other options</span></span><br><span class="line">  &lt;app jar | python file | R file&gt; \</span><br><span class="line">  [application-arguments]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 클러스터 매니저가 yarn인 경우 실행 방법 </span></span><br><span class="line"><span class="comment"># JAR 파일 실행 </span></span><br><span class="line">$ spark-submit --master yarn \</span><br><span class="line">  --queue spark_queue \</span><br><span class="line">  --class sdk.spark.SparkWordCount \</span><br><span class="line">  --conf spark.shuffle.service.enabled=<span class="literal">true</span> \</span><br><span class="line">  ./Spark-Example.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이썬 파일 실행 </span></span><br><span class="line">$ spark-submit --master yarn \</span><br><span class="line">  --queue spark_queue \</span><br><span class="line">  ./py01.py</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>설정</th><th>비고</th></tr></thead><tbody><tr><td>—master</td><td>클러스터 매니저 설정</td></tr><tr><td>—deploy-mode</td><td>드라이버의 디플로이 모드 설정</td></tr><tr><td>—class</td><td>main 함수가 들어 있는 클래스 지정</td></tr><tr><td>—name</td><td>애플리케이션의 이름 지정. 스파크 웹 UI에 표시</td></tr><tr><td>—jars</td><td>애플리케이션 실행에 필요한 라이브러리 목록. 콤마로 구분</td></tr><tr><td>—files</td><td>애플리케이션 실행에 필요한 파일 목록</td></tr><tr><td>—queue</td><td>얀의 실행 큐이름 설정</td></tr><tr><td>—executor-memory</td><td>익스큐터가 사용할 메모리 바이트 용량. 512m. 1g 등도 사용 가능</td></tr><tr><td>—driver-memory</td><td>드라이버 프로세스가 사용할 메모리 바이트 용량. 512m. 1g 등도 사용 가능</td></tr><tr><td>—num-executors</td><td>익스큐터의 개수 설정</td></tr><tr><td>—executor-cores</td><td>익스큐터의 코어 개수 설정</td></tr></tbody></table></div><h2 id="실제예제"><a href="#실제예제" class="headerlink" title="실제예제"></a>실제예제</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run application locally on 8 cores</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master <span class="built_in">local</span>[8] \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  100</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Spark standalone cluster in client deploy mode</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Spark standalone cluster in cluster deploy mode with supervise</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --supervise \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a YARN cluster in cluster deploy mode</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=XXX</span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --num-executors 50 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run a Python application on a Spark standalone cluster</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  examples/src/main/python/pi.py \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Mesos cluster in cluster deploy mode with supervise</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master mesos://207.184.161.138:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --supervise \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  http://path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Kubernetes cluster in cluster deploy mode</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master k8s://xx.yy.zz.ww:443 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --num-executors 50 \</span><br><span class="line">  http://path/to/examples.jar \</span><br><span class="line">  1000</span><br></pre></td></tr></table></figure><ul><li>로컬모드 &amp; 독립실행형으로는<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME&#x2F;bin&#x2F;spark-submit \</span><br><span class="line">--class org.apche.spark.examples.SparkPi \</span><br><span class="line">--master local \ # 로컬</span><br><span class="line">or</span><br><span class="line">--master spark:&#x2F;&#x2F;mysparkmaster:7077 \ # 독립  </span><br><span class="line">$SPARK_HOME&#x2F;examples&#x2F;jars&#x2F;spark-examples*.jar 10</span><br></pre></td></tr></table></figure></li><li>YARN<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME&#x2F;bin&#x2F;spark-submit \</span><br><span class="line">--class org.apche.spark.examples.SparkPi \</span><br><span class="line">--master yarn</span><br><span class="line">--deploy-mode cluster \ # client 배포모드도있음 </span><br><span class="line">$SPARK_HOME&#x2F;examples&#x2F;jars&#x2F;spark-examples*.jar 10</span><br></pre></td></tr></table></figure></li><li>mesos<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Run on a Mesos cluster in cluster deploy mode with supervise</span><br><span class="line">.&#x2F;bin&#x2F;spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master mesos:&#x2F;&#x2F;207.184.161.138:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --supervise \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  http:&#x2F;&#x2F;path&#x2F;to&#x2F;examples.jar \</span><br><span class="line">  1000</span><br></pre></td></tr></table></figure></li></ul><hr><h1 id="스파크-설치-방법"><a href="#스파크-설치-방법" class="headerlink" title="스파크 설치 방법"></a>스파크 설치 방법</h1><ul><li>리눅스 윈도우 맥OSX 다 가능 8GB+, 8 core 이상 좋음</li><li>JVM에서 실행되도록 compiled scala로 작성되어있어서 JDK설치 필수 </li><li><a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">https://spark.apache.org/downloads.html</a> 에 설치방법 있음 <h2 id="MAC-Linux에-Spark-설치"><a href="#MAC-Linux에-Spark-설치" class="headerlink" title="MAC | Linux에 Spark 설치"></a>MAC | Linux에 Spark 설치</h2></li></ul><ol><li>자바설치<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-8-jdk-headless // Linux</span><br><span class="line">$ brew cask install java</span><br></pre></td></tr></table></figure></li><li>스파크 설치 &amp; tar<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://dlcdn.apache.org/spark/spark-3.4.2/spark-3.4.2-bin-hadoop3.tgz</span><br><span class="line">$ tar zxvf spark-3.4.2-bin-hadoop3.tgz</span><br><span class="line">$ rm -rf spark-3.4.2-bin-hadoop3.tgz</span><br><span class="line">$ sudo mv spark-3.4.2-bin-hadoop3 /opt/spark</span><br></pre></td></tr></table></figure></li><li>환경변수설정<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.zshrc -&gt; <span class="built_in">source</span> ~/.zshrc</span><br><span class="line">or</span><br><span class="line">$ <span class="built_in">export</span> SPARK_HOME=/opt/spark </span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li><li>확인<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ spark-shell</span><br><span class="line">or </span><br><span class="line">$ spark-submit --class org.apche.spark.examples.SparkPi \</span><br><span class="line">--master <span class="built_in">local</span> \ <span class="comment"># 로컬</span></span><br><span class="line"><span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples*.jar 1000</span><br></pre></td></tr></table></figure><h2 id="스파크-at-클라우드"><a href="#스파크-at-클라우드" class="headerlink" title="스파크 at 클라우드"></a>스파크 at 클라우드</h2>EC2, EMR(Elastic Mapreduce)과 대표적인데  EMR이 하이브, 피그, 프레스토, 제플린 등<br>에코시스템 가진 하둡 클러스터라 프로비저닝도 되어서 이거 쓰는거 추천</li></ol>]]></content>
      
      
      <categories>
          
          <category> PySpark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 스터디 </tag>
            
            <tag> PySpark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[PySpark_#1] 파이썬을 활용한 스파크 프로그래밍, (1장/8장)</title>
      <link href="/2024/02/08/pyspark-ch2-3/"/>
      <url>/2024/02/08/pyspark-ch2-3/</url>
      
        <content type="html"><![CDATA[<h1 id="소개"><a href="#소개" class="headerlink" title="소개"></a>소개</h1><p>Spark스터디에 참여할 수 있는 좋은 기회가 생겼다.<br>아래의 책을 여러 명이 읽어보고 정리하면서 서로의 생각을<br>공유하는 스터디 이며 그 첫 장을 여는 포스팅.<br>많이 부족하고 처음 작성해 보는 포스팅이라 서툴 수 있는데<br>열심히 노력해서 다른 분들처럼 멋있는 글을 써보고 싶덩<br><img src="https://velog.velcdn.com/images/devhyung/post/ff036e01-88e8-4423-8272-9e1dd18db6dc/image.png" alt="읽을 책 표지"></p><hr><h1 id="Keywords-amp-Terms"><a href="#Keywords-amp-Terms" class="headerlink" title="Keywords &amp; Terms"></a>Keywords &amp; Terms</h1><ul><li>HDFS(Hadoop Distributed File System)</li><li>YARN(Yet Another Resource Negotiator)</li><li>data locality, shared nothing, map-reduce</li><li>schema-on-write &lt;-&gt; schema-on-read</li><li>RDD(Resilient Destributed Dataset)</li><li>fault-tolerant 내결함성</li></ul><hr><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>책은 8 Chapter지만, 2 Part로 나눌 수 있음.<br><strong>Part 1 - 스파크 기초 (ch.1 ~ ch.4)</strong><br><strong>Part 2 - 스파크 응용 (ch.5 ~ ch.8)</strong><br>1장에서는</p><ul><li>Big Data, Hadoop 소개 </li><li>HDFS, YARN 소개 </li><li>Spark 소개</li><li>PySpark에 필요한 Python 기본<br>을 설명하는 챕터</li></ul><hr><h1 id="PySpark"><a href="#PySpark" class="headerlink" title="PySpark"></a>PySpark</h1><p>이걸 왜 써요 ? 라는 사람들에게 하는 좋은 비유</p><blockquote><p>예전에는 무거운 짐을 싣기 위해서 소를 이용했는데,<br>한 마리의 소를 이용해서 짐을 싣을 수 없을 경우에는<br>더 힘이 센 소를 찾기 보단<br>여러 마리의 소를 이용해 짐을 옮기는 방법이 효율적이지 않나?<br>빅데이터도 그렇다 - 그레이스 호퍼 제독</p></blockquote><h2 id="ㄴ-Big-Data-Hadoop"><a href="#ㄴ-Big-Data-Hadoop" class="headerlink" title="ㄴ Big Data, Hadoop"></a>ㄴ Big Data, Hadoop</h2><h3 id="ㄴㄴ-빅데이터와-하둡의-탄생"><a href="#ㄴㄴ-빅데이터와-하둡의-탄생" class="headerlink" title="ㄴㄴ 빅데이터와 하둡의 탄생"></a>ㄴㄴ 빅데이터와 하둡의 탄생</h3><p>2000년대 구글, 야후가 시작 한 싸움 -&gt;<br>구글은 2003년에 <code>더 구글 파일 시스템</code> 이라는 논문을 시작으로<br>2004년에 Map-Reduce 논문을 발표함 이게 추후의 Hadoop의 시초 -&gt;<br>야후가 2006년 공식적 Hadoop을 채택하고 구글의 인적자원을 가져감</p><h3 id="ㄴㄴ-Hadoop"><a href="#ㄴㄴ-Hadoop" class="headerlink" title="ㄴㄴ Hadoop?"></a>ㄴㄴ Hadoop?</h3><blockquote><p>Hadoop은 데이터 지역성이라는 개념에 바탕을 둔 데이터 저장 및 처리 플랫폼이다<br>=&gt; 책에서는 저렇게 정의를 했는데 내 식으로 다시 정의해보면<br>큰 문제(데이터)를 작은 문제(데이터)로 나눠서 저장 및 문제를 해결하려는<br>좋은 도구 같음</p></blockquote><p><code>데이터지역성(data locality)</code>(이)란 데이터를 호스트로 보내 처리하는 기존 방식과 달리,<br>데이터가 있는 곳으로 이동해서 계산하는 데이터 처리방식임(오? 신박함)</p><p>각 Node는 다른 Node들과 통신 할 필요없이 전체 데이터의 훨씬 작은 부분을 독립적으로<br>처리하면서 분산 파일 시스템의 구현을 통해 해결함<br>이걸 가능하게 하는 게 <code>비공유 접근(shared nothing)</code>개념<br><code>schema-on-read</code>시스템으로 스키마가 따로 없기에 광범위한 데이터를 저장하고 처리 할 수 있는게 특징임</p><h3 id="ㄴㄴ-Component-of-Hadoop"><a href="#ㄴㄴ-Component-of-Hadoop" class="headerlink" title="ㄴㄴ Component of Hadoop"></a>ㄴㄴ Component of Hadoop</h3><ul><li><strong>HDFS</strong>(Hadoop Distributed File System) : 하둡의 스토리지 서브시스템</li><li><strong>YARN</strong>(Yet Another Resource Negotiator) : 하둡의 프로세싱 또는 리소스 스케줄링 서브시스템</li><li>Flume, Sqoop = 데이터 처리 프로젝트</li><li>Pig, Hive = 데이터 분석 툴<br>하둡과 상호 작용하거나 통합하는 프로젝트를 <strong>하둡에코시스템</strong> 이라고 함.<br><em>*근데 스파크는 하둡을 실행 할 필요가 없어서 에코시스템인지 논란의 여지가 있음</em></li></ul><hr><h2 id="ㄴ-HDFS-YARN-소개"><a href="#ㄴ-HDFS-YARN-소개" class="headerlink" title="ㄴ HDFS, YARN 소개"></a>ㄴ HDFS, YARN 소개</h2><h3 id="ㄴㄴ-HDFS"><a href="#ㄴㄴ-HDFS" class="headerlink" title="ㄴㄴ HDFS"></a>ㄴㄴ HDFS</h3><p>클러스터의 하나 이상의 노드에 파일이 분산되어 있는 블럭으로 구성된 가상 파일 시스템<br><img src="https://velog.velcdn.com/images/devhyung/post/ba9a9059-7d8f-49e8-ac4f-82f04f889a51/image.png" alt=""><br>적재 프로세스 설명</p><ul><li>Ingestion 프로세스는 설정한 블록크기에 따라 파일을 나눔 </li><li>노드 간 분산 및 복제해서 fault-tolerance 달성하고 로컬에서 처리</li><li>HDFS블록은 <code>DN:데이터노트</code>라는 슬레이브 노드에 저장 및 관리됨</li><li>이런 정보들은 <code>NN:네임노드</code>라는 HDFS 마스터 노드 상주 메모리에 <code>MD:메타데이터</code>로 저장</li><li><code>네임노드</code>는 RDB 트랜잭션로그처럼 저널링함수를 통해 <code>메타데이터</code>위치 제공(맵핑테이블 느낌)<br><img src="https://velog.velcdn.com/images/devhyung/post/3dbeb6b0-f8e9-4937-a2fe-246c764db6af/image.png" alt=""></li></ul><h3 id="ㄴㄴ-YARN"><a href="#ㄴㄴ-YARN" class="headerlink" title="ㄴㄴ YARN"></a>ㄴㄴ YARN</h3><p>YARN은 Hadoop의 데이터를 처리하고 스케쥴링하는 역할</p><blockquote><p>뜻이 궁금해서 쳐봤는데<br>“Yet another”는 일반적으로 이미 많은 것들이 존재하고 있는 상황에서 추가로 하나를 가리키는 표현입니다. 따라서 “yet another resource negotiation”은 이미 다른 자원 협상이 있었음에도 불구하고 추가로 하나가 이루어지고 있다는 의미를 갖는다고 합니다 </p></blockquote><p>설명하는 도식은 아래<br><img src="https://velog.velcdn.com/images/devhyung/post/a5173f5d-1600-4119-9378-ec6607877bae/image.png" alt=""><br>순서를 설명하면</p><ul><li>1) 클라이언트 -&gt; <code>리소스 매니저</code> 작업 시킴</li><li>2) <code>리소스 매니저</code>는 <code>노드매니저</code>에게, <code>애플리케이션 마스터(AM)</code>을 할당</li><li>3) <code>AM</code>은 실행할 작업컨테이너 협상하고 관리할 <code>노드매니저</code>로 전달 </li><li>4) <code>노드매니저</code>는 (2)의<code>AM</code>에게 보고</li><li>5) <code>AM</code>은 (1)의<code>리소스매니저</code>에게 보고</li><li>6) <code>리소스 매니저</code>는 클라에게 보고 </li><li>자세한건 3장에 있음 </li></ul><p>보통 8088에 웹 UI를 제공</p><hr><h2 id="ㄴ-Spark-소개"><a href="#ㄴ-Spark-소개" class="headerlink" title="ㄴ Spark 소개"></a>ㄴ Spark 소개</h2><p>Hadoop의 맵리듀스 구현에 대안으로 만들어져 매우 효율적이라고 함<br>특징 </p><ul><li>맵리듀스를 대체할 수 있는 리소스 스케줄링, 오케스트레이션 시스템을 검토하도록 설계</li><li>맵리듀스 대안으로 스파크는 RDD(Resilient Destributed Dataset) 탄력적인 분산 데이터 집합이라고 분리는 분산형, 내결함성(fault-tolerant), 인메모리 구조를 구현</li><li>스칼라로 작성되어있고 JVM에서 실행됨 </li><li>파이썬이랑 스칼라 인터프리터식으로 쿼리가능 </li><li>Hadoop의 데이터 처리 프레임워크로 Spark를 배포할 수 있음(일반적으로는 HDFS 인데)</li></ul><hr><h2 id="ㄴ-PySpark를-위한-기초-python"><a href="#ㄴ-PySpark를-위한-기초-python" class="headerlink" title="ㄴ PySpark를 위한 기초 python"></a>ㄴ PySpark를 위한 기초 python</h2><p>여기서는 어느정도 python을 안다고 가정하고 다른 부분만 기술함 </p><ul><li>스파크RDD list 객체는 변경이 안됨</li><li>tuple은 같은데, Spark에선 키/값 쌍으로 많이 쓴다고함(? 왜 dict냅두고)</li><li>dict는 RDD에서 <strong>고정객체</strong>로 쓸수 있다고 함(? 고정객체는 뭐지)</li><li>피클은 파이썬의 특징적인 직렬화 메소드, Json 보다 빠른데 PySpark에서 많이 프로세스간 데이터 전송하는데 많이 쓴다고함</li><li>익명함수 &amp; Lambda를 많이 쓴다고 함 실제 예는 아래에 기술</li><li>클로저함수도 많이 씀, 분산환경에서 중요한 이점을 가질 수 있다는데 함수 구성에따라 오히려 독이 될수도 있다고함 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lines &#x3D; sc.textFile(&quot;YOUR&#x2F;DIR&#x2F;FILE&quot;)</span><br><span class="line">counts &#x3D; lines.flatMap(lambda x: x.split(&#39; &#39;)) \ </span><br><span class="line">.filter(lambda x: len(x) &gt; 0) \</span><br><span class="line">    .map(lambda x: (x, 1)) \ </span><br><span class="line">    .reduceByKey(lambda x, y: x+y) \</span><br><span class="line">    .collect()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>대략 파일을 읽고 띄어쓰기단위로 split했을때 len()이 1개이상인 애들을 필터링해서<br>reduce하는 느낌이네 </li></ul><hr><h1 id="Why"><a href="#Why" class="headerlink" title="Why?"></a>Why?</h1><p>위 챕터랑 정리를하면서 궁금증이 남는 것 + 알아봤으면 좋겠는 걸 따로 기록</p><ul><li>[ ] 왜 굳이 같은 데이터(블록)을 복제해서 저장할까? 유실될까 걱정? 아니면 블록체인식의 저장방법인건지 </li><li>[ ] 그렇다면 몇개까지 복제하는게 최적화된 복제블록일까? 너무 많으면 오버해서 저장하는 거 같고 너무 적으면 나누는 의미가 있을까 싶은데 이것도 국룰적인 복제개수가 존재할까 ? </li><li>[ ] 클로저 펑션을 왜 써야하는지 사실 이해가 되진않음. 이게 왜 분산된환경에서 쓰면 이점이 있으려나 </li></ul><hr><h1 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h1><p>다음은 위의 Why세션에 대한 조사와,<br>2장 스파크 배포 에 대해서 포스팅 할 예정입니다 ~ </p>]]></content>
      
      
      <categories>
          
          <category> PySpark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 스터디 </tag>
            
            <tag> PySpark </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
